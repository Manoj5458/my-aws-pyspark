{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py-9cUe2G2al"
   },
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RegCsaNreucq"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, year\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MonitorAnalysis\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.11.901\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"ACCESS_KEY\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"SECRET_KEY\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.metastore.metrics.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.io.native.lib.available\", \"false\")\\\n",
    "    .config(\"spark.executor.memory\", \"4g\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.region\", \"ap-south-1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50XYqgxoG6iM"
   },
   "source": [
    "**OS Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssrrJzeJGjMu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'ACCESS_KEY'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'SECRET_KEY'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'ap-south-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BveTS6oNHA5N"
   },
   "source": [
    "**Boto Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1NFK4PJGydc",
    "outputId": "896c8cfa-2b5b-4c5b-a3d2-feb4f4b0e949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.35.55)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.55 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.35.55)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.55->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.55->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.55->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwXMea5wG_ws"
   },
   "source": [
    "Boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bw2sQSUTGt2d"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create a session with your credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='ACCESS_KEY',\n",
    "    aws_secret_access_key='SECRET_KEY',\n",
    "    region_name='ap-south-1'  # e.g., 'us-east-1'\n",
    ")\n",
    "\n",
    "dynamodb = session.resource('dynamodb')\n",
    "table = dynamodb.Table('customers')\n",
    "# anomaly_table = dynamodb.Table('anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZOxmUgcPf1G"
   },
   "source": [
    "# RetailMart wants to add insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pgELY9unK8XI"
   },
   "outputs": [],
   "source": [
    "response = table.scan()\n",
    "cust_data = response['Items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZyoHZ-IoMrYI"
   },
   "outputs": [],
   "source": [
    "# Convert the DynamoDB items to DataFrame\n",
    "cust_df = spark.createDataFrame(cust_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jPQ7a7SEMvk4"
   },
   "outputs": [],
   "source": [
    "# Load data from s3\n",
    "sales_input = \"s3a://this-is-my-bucket007/transactions.csv\"\n",
    "trans_df = spark.read.csv(sales_input, header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VEp9k0l2NASx",
    "outputId": "6b32884e-2ede-4921-b495-6dfd99ec609b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Data from DynamoDB:\n",
      "+-----------+-------------+--------------+\n",
      "|customer_id|customer_name|      inactive|\n",
      "+-----------+-------------+--------------+\n",
      "|       C125|        manoj|{BOOL -> true}|\n",
      "|       C126|          Leo|{BOOL -> true}|\n",
      "|       C123|         John|{BOOL -> true}|\n",
      "|       C124|        brock|{BOOL -> true}|\n",
      "+-----------+-------------+--------------+\n",
      "\n",
      "Transaction Data from S3:\n",
      "+--------------+-----------+----------------+------+----------------+\n",
      "|transaction_id|customer_id|transaction_date|amount|product_category|\n",
      "+--------------+-----------+----------------+------+----------------+\n",
      "|          T001|       C123|      2024-01-15|  1200|     Electronics|\n",
      "|          T002|       C124|      2024-01-16|   800|        Clothing|\n",
      "|          T003|       C125|      2024-01-17|  1500| Home Appliances|\n",
      "|          T004|       C123|      2024-01-18|  2000|     Electronics|\n",
      "|          T005|       C126|      2024-01-19|   500|           Books|\n",
      "|          T006|       C127|      2024-01-20|   300|        Clothing|\n",
      "|          T007|       C123|      2024-01-21|  4000|       Furniture|\n",
      "|          T008|       C125|      2024-01-22|   200|           Books|\n",
      "|          T009|       C124|      2024-01-23|  1800|     Electronics|\n",
      "|          T010|       C128|      2024-01-24|   700|        Clothing|\n",
      "+--------------+-----------+----------------+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Customer Data from DynamoDB:\")\n",
    "cust_df.show()\n",
    "print(\"Transaction Data from S3:\")\n",
    "trans_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4CcgfLEDQehd"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5bFasUzPhDZ",
    "outputId": "54931d96-b929-4d5b-c604-f7533c0b1f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase frequency per category for each customer\n",
      "+-----------+----------------+--------------+\n",
      "|customer_id|product_category|purchase_count|\n",
      "+-----------+----------------+--------------+\n",
      "|       C125|           Books|             1|\n",
      "|       C124|     Electronics|             1|\n",
      "|       C123|       Furniture|             1|\n",
      "|       C124|        Clothing|             1|\n",
      "|       C126|           Books|             1|\n",
      "|       C127|        Clothing|             1|\n",
      "|       C128|        Clothing|             1|\n",
      "|       C125| Home Appliances|             1|\n",
      "|       C123|     Electronics|             2|\n",
      "+-----------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate purchase frequency per category for each customer\n",
    "category_count_df = (\n",
    "    trans_df.groupBy(\"customer_id\", \"product_category\").agg(count(\"product_category\").alias(\"purchase_count\"))\n",
    ")\n",
    "print(\"purchase frequency per category for each customer\")\n",
    "category_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YnWjujDEQ3M9"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, sum, avg, row_number, desc\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ami9iOWMQ1bt",
    "outputId": "1d8dce50-ff1b-4d89-a0ed-84fa41dd2dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequently bought category for each customer\n",
      "+-----------+----------------+\n",
      "|customer_id|product_category|\n",
      "+-----------+----------------+\n",
      "|       C123|     Electronics|\n",
      "|       C124|     Electronics|\n",
      "|       C125|           Books|\n",
      "|       C126|           Books|\n",
      "|       C127|        Clothing|\n",
      "|       C128|        Clothing|\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine the most frequently bought category for each customer\n",
    "favorite_category_df = (\n",
    "    category_count_df\n",
    "    .withColumn(\"rank\", row_number().over(Window.partitionBy(\"customer_id\").orderBy(desc(\"purchase_count\"))))\n",
    "    .filter(col(\"rank\") == 1)\n",
    "    .select(\"customer_id\", \"product_category\")\n",
    ")\n",
    "print(\"most frequently bought category for each customer\")\n",
    "favorite_category_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tIsX2tWORDYM"
   },
   "outputs": [],
   "source": [
    "# Collect and update each customer's favorite category in DynamoDB\n",
    "for row in favorite_category_df.collect():\n",
    "    table.update_item(\n",
    "        Key={\"customer_id\": row[\"customer_id\"]},\n",
    "        UpdateExpression=\"SET favorite_category = :category\",\n",
    "        ExpressionAttributeValues={\":category\": row[\"product_category\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g44mIGWNRF18",
    "outputId": "995dbadd-2b4b-404d-9b53-4d2aa3dde139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favorite product category updated for each customer in DynamoDB.\n"
     ]
    }
   ],
   "source": [
    "print(\"Favorite product category updated for each customer in DynamoDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvq9f1ytRIlF"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
